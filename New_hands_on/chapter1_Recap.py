
# 1장. 개념정리


# 1.1 머신러닝 이란?

# 어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면,
# 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다.
# 훈련세트(경험 E) : 시스템이 학습하는데 사용하는 샘플
# 정확도(성능 측정 P) : 성능 측정, 상황에 따른 지표가 성능 측정의 지표가 됨.


# 1.2 왜 머신러닝을 사용하는가?

# "자동으로 감지한다는 장점"
# (+) 데이터 마이닝 : 머신러닝 기술을 적용하여 대용량의 데이터를 분석하면 겉으로는 보이지 않는 패턴을 발견
# 유용한 분야
# 1. 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제
# 2. 전통적인 방식으로는 해결 방법이 없는 복잡한 문제
# 3. 유동적인 환경
# 4. 복잡한 문제와 대량의 데이터에서 통찰 얻기


# 1.4 머신러닝의 종류

# 요약
# 1. 사람의 감독하에 훈련하는 것인지 아닌지 -> 지도, 비지도, 준지도, 강화학습
# 2. 실시간으로 점진적인 학습 -> 온라인, 배치학습
# 3. 단순하게 알고 있는 데이터 포인트와 새 데이터 포인트를 비교하는 지
# 아니면 과학자들이 하는 것처럼 훈련 데이터셋에서 패턴을 발견하여 예측 모델 만드는지
# -> 사례 기반, 모델 기반 학습

# 1. 지도 학습
# 알고리즘에 주입하는 훈련 데이터에 '레이블'이라는 원하는 답이 포함.
# 종류 : 분류, 회귀 (특성(예측변수)을 사용해 타깃수치를 예측.)
# (+) 일부 회귀는 분류로도 사용가능.
# 예시 : K-최근접 이웃, 선형 회귀, 로지스틱 회귀, 서포트 벡터 머신(SVM), 결정트리와 랜덤 포레스트, 신경망

# 2. 비지도 학습
# 훈련 데이터에 '레이불'이 없다.
# 종류 및 예시
# 1. 군집
# - K-평균
# - DBSCAN
# - 계층 군집 분석(HCA)
# - 이상치 탐지와 특이치 감지
# - 원-클래스
# - 아이솔레이션 포레스트
# 2. 시각화와 차원축소
# - 주성분 분석(PCA)
# - 지역적 선형 임베딩(LLE)
# - t-SNE
# 3. 연관 규칙 학습
# - 어프라디어리
# - 이클렛

# 간단한 예시
# 계층 군집, 시각화, 차원축소, 특성추출, 이상치 탐지(이상한 값 감지), 특이치 탐지(샘플간 이상 값 감지),
# 연관 규칙 학습(특성간 흥미로운 관계 찾음, 바베큐 소스를 사는 사람들은 대부분 바베큐 고기를 산다.)

# 이상치 감지 vs 특이치 감지
# 강아지 사진들 속 치와와
# 이상치 감지 -> 치와와를 이상치로 분류
# 특이치 감지 -> 그냥 강아지로 생각하고 분류 안함.

# 3. 준지도 학습
# 일부만 '레이블'이 있는 경우
# ex) 가족 사진 데이터가 있다고 가정햿을 때, 구성원 A가 어떤 사진에 있는지 알아냄
# 하지만 이름은 모름.
# 지도학습과 비지도 학습의 조합

# 4. 강화학습
# 시스템(에이전트)이 환경을 관찰해서 행동을 실행하고 그 결과로 보상 또는 벌접을 받는다.
# 시간이 지나면서 가장 큰 보상을 얻기 위해 정책이라고 부르는 최상의 전략을 스스로 학습한다. 
# 과정 : 관찰-정책에 따라 행동 선택-행동실행-보상이나 벌점-정책 수정-최적의 정책을 찾을 때가지 반복
# 예시 : 알파고, 보행 로봇

# 5. 배치학습(오프라인 학습)
# 점진적으로 데이터를 학습하는 것이 아닌 가용한 데이터를 모두 사용해 훈련
# 시간과 자원을 많이 소모하므로 오프라인에서 수행
# 새로운 데이터에 대해 학습하려면 전체 데이터를 사용하여 시스템의 새로운 버전을 처음부터 다시 훈련
# 이 후, 이전 시스템을 중지시키고 새 시스템으로 교체
# 자원이 한정되고 데이터 변화량이 많은 프로그램일수록 점진적 학습이 나음.

# 6. 점진적 학습(온라인 학습)
# 데이터를 미니배치라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련
# 매 학습 단계가 빠르고 비용이 적게 든다는 장점, 컴퓨터 자원이 한정적일때 좋은 선택
# 연속적으로 데이터를 받으며 학습이 끝난 데이터는 버리면 되므로 공간절약.
# 빠른 변화에 적응해야 하는 시스템에 적합한 학습 방법.
# 알고리즘이 데이터 일부를 읽어 들이고 훈련 단계를 수행, 전체 데이터가 모두 적용될 때까지 이 과정 반복

# (+) 학습률 - 변화하는 데이터에 얼마나 빠르게 적응할 것인가
# 학습률을 높게 하면 -> 시스템이 데이터에 빠르게 적응하지만 예전 데이터를 금방 잊어버림
# (ex, 스팸 메시지에 대해 교육하다보면 예전 방식의 스팸메시지는 구별 못하게 됨)
# 학습률을 낮게 하면 -> 시스템이 느려지지만 문제 있는 데이터에 덜 민감

# 점진적 학습(온라인 학습)의 문제점
# 나쁜 데이터가 주입되었을 때, 성능이 점진적으로 감소, 즉 나쁜 데이터에 민감
# 해결책 - 시스템 모니터링, 성능 감지가 발견되면 즉각 학습 종료, 입력 데이터를 모니터링(이상치 탐지 알고리즘 등으로)

# 6. 사례 기반 학습(유사도 측정을 통한 에측)
# 시스템이 훈련 샘플을 기억함으로써 학습.
# 유사도 측정을 사용해 새로운 데이터와 학습한 샘플을 비교하는 방식으로 일반화(새로운 데이터에 대한 예측)

# 7. 모델 기반 학습(모델을 만들어 예측)
# 샢플들의 모델을 만들어 예측에 사용한다.
# 예시
# 모델 선택 - 1인당 GDP의 선형함수로 삶의 만족도를 모델링
# -> 1인당 GDP라는 특성 하나를 가진 삶의 만족도에 대한 '선형 모델'
# 과정
# 1. 데이터 분석
# 2. 모델 선택
# 3. 훈련 데이터로 모델 훈련
# 4. 새로운 데이터에 모델을 적용해 예측을 하고 모델이 잘 일반화 되기를 기대한다.
# 모델 평가 방법
# 효용 함수 - 모델이 얼마나 좋은지 측정
# 비용 함수 - 모델이 얼마나 나쁜지 측정
# ex) 선형 회귀에서는 선형 모델의 예측과 훈련 데이터 사이의 거리를 재는 비용함수를 측정하고
# 이 거리를 최소화하는 것을 목표로 한다.



# 1.5 머신러닝의 주요 도전 과제
# 나쁜 알고리즘, 나쁜 데이터 방지


# 나쁜 데이터의 사례

# 1. 충분하지 않은 양의 훈련 데이터

# 2. 대표성 없는 훈련 데이터
# 새로운 사례를 훈련 데이터가 잘 대표하는 것이 중요
# 샘플링 잡음 - 샘플이 작을때, 우연에 의한 대표성이 없는 데이터가 생김
# ex) 1인당 GDP에 따라 행복도 조사하는데 몇가지의 나라를 빼먹음
# 샘플링 편향 - 매우 큰 샘플도 표본 추출 방법이 잘못되면 대표성을 띄지 못함
# ex) 출구 조사를 여러 계층이 아닌 부유한 계층만 많이 조사함.

# 3. 나쁜 품질의 데이터
# 에러, 이상치, 잡음이 많은 데이터
# 해결책 - 데이터 정제
# 3-1. 무시하거나 수동으로 고침
# 3-2. 이 특성을 모두 무시할지, 이 샘플만 무시할지, 빠진 값을 채울지(예를들어 평균으로),
# 특성을 넣은 모델과 제외한 모델을 따로 훈련시킬지 결정

# 4. 관련 없는 특성
# 툭성 선택 : 가지고 있는 특성 중 훈련에 가장 유용한 특성을 선택
# 특성 추출 : 특성을 결합하여 더 유용한 특성을 만든다. (ex, 차원 축소 알고리즘)
# 새로운 데이터를 수집해 새 특성을 만든다.


# 나쁜 알고리즘의 사례

# 1. 훈련 데이터 과대 적합
# 모델이 훈련 데이터에 너무 잘 맞지만 그 결과를 일반화하기에는 어렵다
# 해결책
# 1-1. 파리마터 수가 적은 모델을 선택
# 1-2. 훈련데이터의 특성수를 줄인다.
# 1-3. 모델에 제약을 가하여 단순화(규제 - 파라미터에 자유도를 조정)
# 1-4. 훈련데이터를 많이 모은다
# 1-5. 훈련데이터의 잡음을 줄인다.
# (+) 규제의 양은 하이퍼파라미터가 결정.
# 하이퍼파라미터는 모델파라미터가 아닌 학습 알고리즘의 파라미터

# 2. 훈련 데이터 과소 적합
# 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할때 일어난다.
# 해결책
# 2-1. 모델 파라미터가 더 많은 강력한 모델을 선택
# 2-2. 학습 알고리즘에 더 좋은 특성을 제공
# 2-3. 모델의 제약을 줄인다(예를들어, 하이퍼파라미터를 감소시킨다.)


# 1.6 테스트와 검증
# 훈련세트와 테스트 세트 나누기 - 일반화 오차로 평가(테스트 세트의 예측과 테스트 세트의 실제 값 비교)
# 하이퍼파라미터 튜닝과 모델 선택
# 모델 선택시 - 교차 검증
# 교차검증은 여러번의 홀드아웃 검증을 하는 것.
# ex) 데이터파트가 (1, 2, 3, 4, 5)
# 1,2,3 으로 훈련 후 4,5로 평가 - 1,3,5로 훈련 후 2,4로 평가
# 이 후 평가들의 평균으로 모델 평가
